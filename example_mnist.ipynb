{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example on MNIST\n",
    "\n",
    "This example illustrates how ZerO works and avoids the training degeneracy (described by Thereom 1 in the paper). \n",
    "\n",
    "Link of the paper: https://arxiv.org/abs/2110.12661"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import numpy as np\n",
    "import math\n",
    "from scipy.linalg import hadamard\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model\n",
    "We consider a 4-layer multi-layer perceptron (MLP) where the hidden dimension is fixed. The models based on **random, partial identity, and ZerO** initialization are defined as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ZerO_Init_on_matrix(matrix_tensor):\n",
    "    # Algorithm 1 in the paper.\n",
    "    \n",
    "    m = matrix_tensor.size(0)\n",
    "    n = matrix_tensor.size(1)\n",
    "    \n",
    "    if m <= n:\n",
    "        init_matrix = torch.nn.init.eye_(torch.empty(m, n))\n",
    "    elif m > n:\n",
    "        clog_m = math.ceil(math.log2(m))\n",
    "        p = 2**(clog_m)\n",
    "        init_matrix = torch.nn.init.eye_(torch.empty(m, p))\\\n",
    "                    @ (torch.tensor(hadamard(p)).float()/(2**(clog_m/2)))\\\n",
    "                    @ torch.nn.init.eye_(torch.empty(p, n))\\\n",
    "    \n",
    "    return init_matrix\n",
    "\n",
    "def Identity_Init_on_matrix(matrix_tensor):\n",
    "    # Definition 1 in the paper\n",
    "    # See https://pytorch.org/docs/stable/nn.init.html#torch.nn.init.eye_ for details. Preserves the identity of the inputs in Linear layers, where as many inputs are preserved as possible, the same as partial identity matrix.\n",
    "    \n",
    "    m = matrix_tensor.size(0)\n",
    "    n = matrix_tensor.size(1)\n",
    "    print(\"Init matrix\", matrix_tensor.shape, \"with m={}, n={}\".format(m, n))\n",
    "    \n",
    "    init_matrix = torch.nn.init.eye_(torch.empty(m, n))\n",
    "    \n",
    "    return init_matrix\n",
    "\n",
    "def OnE_Init_on_matrix(matrix_tensor):\n",
    "    m = matrix_tensor.size(0)\n",
    "    n = matrix_tensor.size(1)\n",
    "    init_matrix = torch.nn.init.eye_(torch.empty(m,n))\n",
    "    if m <= n:\n",
    "        print(\"Nothing extra to be done to OnE-Initialize\", init_matrix.shape);\n",
    "    elif m > n:\n",
    "        print(\"OnE-Initializing\", init_matrix.shape)\n",
    "        init_matrix = torch.nn.init.eye_(torch.empty(m,n))\n",
    "        rng = np.random.default_rng()\n",
    "        for row in range(n, m, 1):\n",
    "            col = rng.integers(low=0, high=n-1, endpoint=True)\n",
    "            #print(\"Random column selected to be initialized to OnE (0 to {}): {}\".format(n-1, col))\n",
    "            init_matrix[row, col] = 1\n",
    "    else:\n",
    "        assert(False)\n",
    "    return init_matrix\n",
    "            \n",
    "\n",
    "def Spray_Init_on_matrix(matrix_tensor):\n",
    "    \"\"\" Fill like OnE init, but invert effect\"\"\"\n",
    "    m = matrix_tensor.size(0)\n",
    "    n = matrix_tensor.size(1)\n",
    "    init_matrix = torch.nn.init.eye_(torch.empty(m,n))\n",
    "    if m <= n:\n",
    "        print(\"Nothing extra to be done to OnE-Initialize\", init_matrix.shape);\n",
    "    elif m > n:\n",
    "        print(\"OnE-Initializing\", init_matrix.shape)\n",
    "        init_matrix = torch.nn.init.eye_(torch.empty(m,n))\n",
    "        rng = np.random.default_rng()\n",
    "        for row in range(n, m, 1):\n",
    "            col = rng.integers(low=0, high=n-1, endpoint=True)\n",
    "            #print(\"Random column selected to be initialized to OnE (0 to {}): {}\".format(n-1, col))\n",
    "            init_matrix[row, col] = 1\n",
    "    else:\n",
    "        assert(False)\n",
    "    # Invert effect\n",
    "    fix_value = 1 / (n-1)\n",
    "    print(\"Spray initializing to value {}\".format(fix_value))\n",
    "    init_matrix = fix_value * (torch.ones(m,n) - init_matrix)\n",
    "    return init_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    '''\n",
    "    a standard model with 4 hidden layers\n",
    "    '''\n",
    "    def __init__(self, n_h=1024, init='ZerO'):\n",
    "        super(MLP, self).__init__()\n",
    "        self.init = init\n",
    "        self.n_h = n_h\n",
    "        self.l1 = nn.Linear(784, 784, bias=False)  \n",
    "        self.l2 = nn.Linear(784, self.n_h, bias=False)  \n",
    "        self.l3 = nn.Linear(self.n_h, self.n_h, bias=False)  \n",
    "        self.l4 = nn.Linear(self.n_h, 10, bias=False)  \n",
    "\n",
    "        self.apply(self._init_weights)\n",
    "        \n",
    "    def forward(self, x): \n",
    "\n",
    "        x = x.view(-1, 28 * 28)\n",
    "        x = self.l1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.l2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.l3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.l4(x)\n",
    "        return F.log_softmax(x)\n",
    "    \n",
    "    def _init_weights(self, m):\n",
    "        \n",
    "        if self.init == 'ZerO':\n",
    "            if isinstance(m, nn.Linear):\n",
    "                m.weight.data = ZerO_Init_on_matrix(m.weight.data)\n",
    "                \n",
    "        elif self.init == 'Partial_Identity':\n",
    "            if isinstance(m, nn.Linear):\n",
    "                m.weight.data = Identity_Init_on_matrix(m.weight.data)\n",
    "        \n",
    "        elif self.init == 'Random':\n",
    "            if isinstance(m, nn.Linear):\n",
    "                torch.nn.init.kaiming_normal_(m.weight)\n",
    "        elif self.init == 'OnE':\n",
    "            if isinstance(m, nn.Linear):\n",
    "                m.weight.data = OnE_Init_on_matrix(m.weight.data)\n",
    "        elif self.init == 'Spray':\n",
    "            if isinstance(m, nn.Linear):\n",
    "                m.weight.data = Spray_Init_on_matrix(m.weight.data)\n",
    "        else:\n",
    "            assert(False)\n",
    "                \n",
    "        if isinstance(m, nn.Linear) and m.bias is not None:\n",
    "            nn.init.constant_(m.bias, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rank(tensor):\n",
    "\n",
    "    tensor = tensor.detach().cpu()\n",
    "    rank = np.linalg.matrix_rank(tensor, tol=0.0001)\n",
    "    \n",
    "    return rank\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Pipeline on MNIST\n",
    "\n",
    "from https://github.com/pytorch/examples/blob/main/mnist/main.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verification of Theorem 1 (Figure 3 in the paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimizer(torch.optim.SGD):\n",
    "    def step(self, closure=None):\n",
    "        loss = None\n",
    "        if closure is not None:\n",
    "            loss = closure()\n",
    "\n",
    "        for group in self.param_groups:\n",
    "            for p in group['params']:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                \n",
    "                d_p = p.grad.data\n",
    "                p.data.add_(d_p, alpha=-group['lr']) \n",
    "\n",
    "        return loss\n",
    "\n",
    "def train(args, model, device, train_loader, optimizer, epoch, train_acc_list, train_loss_list, rank_list_dict):\n",
    "    model.train()\n",
    "    correct = 0\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        pred = output.argmax(dim=1, keepdim=True)\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "        loss.backward()\n",
    "        optimizer.step()        \n",
    "        if batch_idx % args.log_interval == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\tAccuracy({:.0f}%)'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item(),\n",
    "                100. * correct / len(train_loader.dataset)))\n",
    "            \n",
    "            # log metric\n",
    "            train_acc_list.append(100. * correct / len(train_loader.dataset))\n",
    "            train_loss_list.append(loss.item())\n",
    "            for name, param in model.named_parameters():\n",
    "                if param.grad is not None:\n",
    "                    if 'l3' in name:\n",
    "                        if name not in rank_list_dict:\n",
    "                            rank_list_dict[name] = []\n",
    "                            \n",
    "                        # compute stable rank of the residual component\n",
    "                        rank_list_dict[name].append(compute_rank(param.data - torch.eye(param.data.size(0)).to(param.data.device)))\n",
    "                \n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "\n",
    "    return 100. * correct / len(test_loader.dataset)\n",
    "\n",
    "\n",
    "def train_model(model, file_dir=None):\n",
    "    # Training settings\n",
    "    parser = argparse.ArgumentParser(description='PyTorch MNIST Example')\n",
    "    parser.add_argument('--batch-size', type=int, default=64, metavar='N',\n",
    "                        help='input batch size for training (default: 64)')\n",
    "    parser.add_argument('--test-batch-size', type=int, default=1000, metavar='N',\n",
    "                        help='input batch size for testing (default: 1000)')\n",
    "    parser.add_argument('--epochs', type=int, default=1, metavar='N',\n",
    "                        help='number of epochs to train (default: 14)')\n",
    "    parser.add_argument('--lr', type=float, default=0.1, metavar='LR',\n",
    "                        help='learning rate (default: 1.0)')\n",
    "    parser.add_argument('--gamma', type=float, default=0.7, metavar='M',\n",
    "                        help='Learning rate step gamma (default: 0.7)')\n",
    "    parser.add_argument('--no-cuda', action='store_true', default=True,\n",
    "                        help='disables CUDA training')\n",
    "    parser.add_argument('--seed', type=int, default=1, metavar='S',\n",
    "                        help='random seed (default: 1)')\n",
    "    parser.add_argument('--log-interval', type=int, default=50, metavar='N',\n",
    "                        help='how many batches to wait before logging training status')\n",
    "\n",
    "    parser.add_argument('--save-model', action='store_true', default=False,\n",
    "                        help='For Saving the current Model')\n",
    "\n",
    "    parser.add_argument('--name', type=str, default='test')  \n",
    "    \n",
    "    parser.add_argument('--init', type=str, default='ZerO') \n",
    "\n",
    "    args = parser.parse_args([])\n",
    "    print(\"Parsed args:\", args)\n",
    "    use_cuda = not args.no_cuda and torch.cuda.is_available()\n",
    "\n",
    "    torch.manual_seed(args.seed)\n",
    "\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST('../data', train=True, download=True,\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                       ])),\n",
    "        batch_size=args.batch_size, shuffle=True, **kwargs)\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                       ])),\n",
    "        batch_size=args.test_batch_size, shuffle=True, **kwargs)\n",
    "\n",
    "    model = model.to(device)\n",
    "    # debug\n",
    "    print(\" ---------- Now training init={} ----------\".format(args.init))\n",
    "    print(\"v ===== Before training (args.init={}) =====\".format(args.init))\n",
    "    for name, params in model.named_parameters():\n",
    "        print(params.shape)\n",
    "        print(name, params.data)\n",
    "    print(\"^ ===== Before training (args.init={}) =====\".format(args.init))   \n",
    "    optimizer = Optimizer(model.parameters(), lr=args.lr)\n",
    " \n",
    "    # logging metric    \n",
    "    train_acc_list = []\n",
    "    train_loss_list = []\n",
    "    rank_list_dict = {}\n",
    "    \n",
    "    scheduler = StepLR(optimizer, step_size=12, gamma=args.gamma)\n",
    "    \n",
    "    for epoch in range(1, args.epochs + 1):\n",
    "        train(args, model, device, train_loader, optimizer, epoch, train_acc_list, train_loss_list, rank_list_dict)\n",
    "        test(model, device, test_loader)\n",
    "        scheduler.step()\n",
    "    # debug2\n",
    "    print(\"v ===== After training (args.init={}) =====\".format(args.init))\n",
    "    for name, params in model.named_parameters():\n",
    "        print(params.shape)\n",
    "        print(name, params.data)\n",
    "    print(\"^ ===== After training (args.init={}) =====\".format(args.init))\n",
    "    optimizer = Optimizer(model.parameters(), lr=args.lr)\n",
    "    if args.save_model:\n",
    "        torch.save(model.state_dict(), args.init + \"_mnist_cnn.pt\")\n",
    "        \n",
    "    return rank_list_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 3 (left): identity initialization under different widths\n",
    "\n",
    "We show that the rank constraints (training degeneracy) happen no matter what the width is. The ranks are always smaller than the input dimension (784=28 * 28)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init matrix torch.Size([784, 784]) with m=784, n=784\n",
      "Init matrix torch.Size([256, 784]) with m=256, n=784\n",
      "Init matrix torch.Size([256, 256]) with m=256, n=256\n",
      "Init matrix torch.Size([10, 256]) with m=10, n=256\n",
      " ---------- Now training init=ZerO ----------\n",
      "v ===== Before training (args.init=ZerO) =====\n",
      "torch.Size([784, 784])\n",
      "l1.weight tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.]])\n",
      "torch.Size([256, 784])\n",
      "l2.weight tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "torch.Size([256, 256])\n",
      "l3.weight tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.]])\n",
      "torch.Size([10, 256])\n",
      "l4.weight tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "^ ===== Before training (args.init=ZerO) =====\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.302585\tAccuracy(0%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13499/2007514160.py:26: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [3200/60000 (5%)]\tLoss: 0.973962\tAccuracy(2%)\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.614879\tAccuracy(6%)\n",
      "Train Epoch: 1 [9600/60000 (16%)]\tLoss: 0.626663\tAccuracy(11%)\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.337751\tAccuracy(15%)\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.646007\tAccuracy(20%)\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.255932\tAccuracy(25%)\n",
      "Train Epoch: 1 [22400/60000 (37%)]\tLoss: 0.715249\tAccuracy(29%)\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.408288\tAccuracy(34%)\n",
      "Train Epoch: 1 [28800/60000 (48%)]\tLoss: 0.407710\tAccuracy(39%)\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.141189\tAccuracy(44%)\n",
      "Train Epoch: 1 [35200/60000 (59%)]\tLoss: 0.129136\tAccuracy(49%)\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.269307\tAccuracy(54%)\n",
      "Train Epoch: 1 [41600/60000 (69%)]\tLoss: 0.133370\tAccuracy(59%)\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.087320\tAccuracy(64%)\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.111893\tAccuracy(69%)\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.283707\tAccuracy(74%)\n",
      "Train Epoch: 1 [54400/60000 (91%)]\tLoss: 0.347303\tAccuracy(79%)\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.116524\tAccuracy(84%)\n",
      "\n",
      "Test set: Average loss: 0.2090, Accuracy: 9346/10000 (93%)\n",
      "\n",
      "v ===== After training (args.init=ZerO) =====\n",
      "torch.Size([784, 784])\n",
      "l1.weight tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.]])\n",
      "torch.Size([256, 784])\n",
      "l2.weight tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "torch.Size([256, 256])\n",
      "l3.weight tensor([[1.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [0.0000e+00, 1.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 1.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
      "         0.0000e+00],\n",
      "        ...,\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.0000e+00, 1.0877e-04,\n",
      "         2.7688e-04],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 1.4778e-04, 1.0011e+00,\n",
      "         2.6847e-03],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 3.5949e-04, 2.5675e-03,\n",
      "         1.0065e+00]])\n",
      "torch.Size([10, 256])\n",
      "l4.weight tensor([[ 1.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.0436e-03,\n",
      "         -1.1127e-02, -2.8481e-02],\n",
      "        [ 0.0000e+00,  1.0000e+00,  0.0000e+00,  ..., -1.5737e-04,\n",
      "         -2.4953e-03, -7.2980e-03],\n",
      "        [ 0.0000e+00,  0.0000e+00,  1.0000e+00,  ...,  1.1354e-03,\n",
      "          1.6651e-02,  3.8486e-02],\n",
      "        ...,\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  4.8922e-03,\n",
      "          4.0179e-02,  1.0234e-01],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -9.3280e-04,\n",
      "         -5.4381e-03, -1.2592e-02],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -3.2588e-03,\n",
      "         -2.4191e-02, -5.4511e-02]])\n",
      "^ ===== After training (args.init=ZerO) =====\n",
      "Init matrix torch.Size([784, 784]) with m=784, n=784\n",
      "Init matrix torch.Size([512, 784]) with m=512, n=784\n",
      "Init matrix torch.Size([512, 512]) with m=512, n=512\n",
      "Init matrix torch.Size([10, 512]) with m=10, n=512\n",
      " ---------- Now training init=ZerO ----------\n",
      "v ===== Before training (args.init=ZerO) =====\n",
      "torch.Size([784, 784])\n",
      "l1.weight tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.]])\n",
      "torch.Size([512, 784])\n",
      "l2.weight tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "torch.Size([512, 512])\n",
      "l3.weight tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.]])\n",
      "torch.Size([10, 512])\n",
      "l4.weight tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "^ ===== Before training (args.init=ZerO) =====\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.302585\tAccuracy(0%)\n",
      "Train Epoch: 1 [3200/60000 (5%)]\tLoss: 0.424199\tAccuracy(4%)\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.469808\tAccuracy(8%)\n",
      "Train Epoch: 1 [9600/60000 (16%)]\tLoss: 0.536723\tAccuracy(13%)\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.266333\tAccuracy(18%)\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.551432\tAccuracy(22%)\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.198503\tAccuracy(27%)\n",
      "Train Epoch: 1 [22400/60000 (37%)]\tLoss: 0.679957\tAccuracy(32%)\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.356694\tAccuracy(37%)\n",
      "Train Epoch: 1 [28800/60000 (48%)]\tLoss: 0.359582\tAccuracy(42%)\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.138990\tAccuracy(47%)\n",
      "Train Epoch: 1 [35200/60000 (59%)]\tLoss: 0.106483\tAccuracy(52%)\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.302657\tAccuracy(57%)\n",
      "Train Epoch: 1 [41600/60000 (69%)]\tLoss: 0.097991\tAccuracy(62%)\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.102183\tAccuracy(67%)\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.108110\tAccuracy(72%)\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.207563\tAccuracy(77%)\n",
      "Train Epoch: 1 [54400/60000 (91%)]\tLoss: 0.338353\tAccuracy(82%)\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.090949\tAccuracy(87%)\n",
      "\n",
      "Test set: Average loss: 0.1751, Accuracy: 9481/10000 (95%)\n",
      "\n",
      "v ===== After training (args.init=ZerO) =====\n",
      "torch.Size([784, 784])\n",
      "l1.weight tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.]])\n",
      "torch.Size([512, 784])\n",
      "l2.weight tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "torch.Size([512, 512])\n",
      "l3.weight tensor([[1.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 1.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 1.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 1.0129, 0.0089, 0.0031],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0160, 1.0194, 0.0145],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0130, 0.0167, 1.0189]])\n",
      "torch.Size([10, 512])\n",
      "l4.weight tensor([[ 1.0000,  0.0000,  0.0000,  ...,  0.0525,  0.0810,  0.1007],\n",
      "        [ 0.0000,  1.0000,  0.0000,  ..., -0.0450, -0.0799, -0.0878],\n",
      "        [ 0.0000,  0.0000,  1.0000,  ...,  0.1250,  0.1324,  0.1657],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ..., -0.0171, -0.0517, -0.0895],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ..., -0.0799, -0.0566,  0.0055],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ..., -0.0518, -0.0706, -0.0737]])\n",
      "^ ===== After training (args.init=ZerO) =====\n",
      "Init matrix torch.Size([784, 784]) with m=784, n=784\n",
      "Init matrix torch.Size([1024, 784]) with m=1024, n=784\n",
      "Init matrix torch.Size([1024, 1024]) with m=1024, n=1024\n",
      "Init matrix torch.Size([10, 1024]) with m=10, n=1024\n",
      " ---------- Now training init=ZerO ----------\n",
      "v ===== Before training (args.init=ZerO) =====\n",
      "torch.Size([784, 784])\n",
      "l1.weight tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.]])\n",
      "torch.Size([1024, 784])\n",
      "l2.weight tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "torch.Size([1024, 1024])\n",
      "l3.weight tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.]])\n",
      "torch.Size([10, 1024])\n",
      "l4.weight tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "^ ===== Before training (args.init=ZerO) =====\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.302585\tAccuracy(0%)\n",
      "Train Epoch: 1 [3200/60000 (5%)]\tLoss: 0.387518\tAccuracy(4%)\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.401102\tAccuracy(9%)\n",
      "Train Epoch: 1 [9600/60000 (16%)]\tLoss: 0.541363\tAccuracy(13%)\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.241735\tAccuracy(18%)\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.560055\tAccuracy(23%)\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.180239\tAccuracy(27%)\n",
      "Train Epoch: 1 [22400/60000 (37%)]\tLoss: 0.678365\tAccuracy(32%)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m n_h_256_rank_list_dict \u001b[38;5;241m=\u001b[39m train_model(MLP(init\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPartial_Identity\u001b[39m\u001b[38;5;124m'\u001b[39m, n_h\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m256\u001b[39m))\n\u001b[1;32m      2\u001b[0m n_h_512_rank_list_dict \u001b[38;5;241m=\u001b[39m train_model(MLP(init\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPartial_Identity\u001b[39m\u001b[38;5;124m'\u001b[39m, n_h\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m))\n\u001b[0;32m----> 3\u001b[0m n_h_1024_rank_list_dict \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mMLP\u001b[49m\u001b[43m(\u001b[49m\u001b[43minit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPartial_Identity\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_h\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1024\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m n_h_2048_rank_list_dict \u001b[38;5;241m=\u001b[39m train_model(MLP(init\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPartial_Identity\u001b[39m\u001b[38;5;124m'\u001b[39m, n_h\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2048\u001b[39m))\n\u001b[1;32m      5\u001b[0m n_h_2048_rank_list_dict_OnE \u001b[38;5;241m=\u001b[39m train_model(MLP(init\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOnE\u001b[39m\u001b[38;5;124m'\u001b[39m, n_h\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2048\u001b[39m))\n",
      "Cell \u001b[0;32mIn[5], line 133\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, file_dir)\u001b[0m\n\u001b[1;32m    130\u001b[0m scheduler \u001b[38;5;241m=\u001b[39m StepLR(optimizer, step_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m12\u001b[39m, gamma\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mgamma)\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, args\u001b[38;5;241m.\u001b[39mepochs \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m--> 133\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_acc_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loss_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrank_list_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    134\u001b[0m     test(model, device, test_loader)\n\u001b[1;32m    135\u001b[0m     scheduler\u001b[38;5;241m.\u001b[39mstep()\n",
      "Cell \u001b[0;32mIn[5], line 20\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(args, model, device, train_loader, optimizer, epoch, train_acc_list, train_loss_list, rank_list_dict)\u001b[0m\n\u001b[1;32m     18\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m     19\u001b[0m correct \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_idx, (data, target) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[1;32m     21\u001b[0m     data, target \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto(device), target\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     22\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    631\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    632\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 633\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    636\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    676\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 677\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    678\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    679\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torchvision/datasets/mnist.py:142\u001b[0m, in \u001b[0;36mMNIST.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    138\u001b[0m img, target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[index], \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtargets[index])\n\u001b[1;32m    140\u001b[0m \u001b[38;5;66;03m# doing this so that it is consistent with all other datasets\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;66;03m# to return a PIL Image\u001b[39;00m\n\u001b[0;32m--> 142\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfromarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mL\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    145\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(img)\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/PIL/Image.py:2701\u001b[0m, in \u001b[0;36mfromarray\u001b[0;34m(obj, mode)\u001b[0m\n\u001b[1;32m   2698\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2699\u001b[0m         obj \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mtostring()\n\u001b[0;32m-> 2701\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfrombuffer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mraw\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrawmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/PIL/Image.py:2636\u001b[0m, in \u001b[0;36mfrombuffer\u001b[0;34m(mode, size, data, decoder_name, *args)\u001b[0m\n\u001b[1;32m   2634\u001b[0m     args \u001b[38;5;241m=\u001b[39m mode, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   2635\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m _MAPMODES:\n\u001b[0;32m-> 2636\u001b[0m     im \u001b[38;5;241m=\u001b[39m \u001b[43mnew\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2637\u001b[0m     im \u001b[38;5;241m=\u001b[39m im\u001b[38;5;241m.\u001b[39m_new(core\u001b[38;5;241m.\u001b[39mmap_buffer(data, size, decoder_name, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m0\u001b[39m, args))\n\u001b[1;32m   2638\u001b[0m     im\u001b[38;5;241m.\u001b[39mreadonly \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/PIL/Image.py:2530\u001b[0m, in \u001b[0;36mnew\u001b[0;34m(mode, size, color)\u001b[0m\n\u001b[1;32m   2526\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m color \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2527\u001b[0m     \u001b[38;5;66;03m# don't initialize\u001b[39;00m\n\u001b[1;32m   2528\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Image()\u001b[38;5;241m.\u001b[39m_new(core\u001b[38;5;241m.\u001b[39mnew(mode, size))\n\u001b[0;32m-> 2530\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcolor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   2531\u001b[0m     \u001b[38;5;66;03m# css3-style specifier\u001b[39;00m\n\u001b[1;32m   2533\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ImageColor\n\u001b[1;32m   2535\u001b[0m     color \u001b[38;5;241m=\u001b[39m ImageColor\u001b[38;5;241m.\u001b[39mgetcolor(color, mode)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_h_2048_rank_list_dict_Spray = train_model(MLP(init='Spray', n_h=2048))\n",
    "n_h_2048_rank_list_dict_OnE = train_model(MLP(init='OnE', n_h=2048))\n",
    "n_h_256_rank_list_dict = train_model(MLP(init='Partial_Identity', n_h=256))\n",
    "n_h_512_rank_list_dict = train_model(MLP(init='Partial_Identity', n_h=512))\n",
    "n_h_1024_rank_list_dict = train_model(MLP(init='Partial_Identity', n_h=1024))\n",
    "n_h_2048_rank_list_dict = train_model(MLP(init='Partial_Identity', n_h=2048))\n",
    "\n",
    "\n",
    "# plotting\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(5,4), gridspec_kw = {'wspace':0.5, 'hspace':0.5})\n",
    "\n",
    "x_axis = np.arange(1, len(n_h_512_rank_list_dict['l3.weight'])+1)\n",
    "x_axis = x_axis * 50\n",
    "\n",
    "# generate a line of 784\n",
    "input_dim_line = np.ones(len(n_h_512_rank_list_dict['l3.weight'])) * 784\n",
    "\n",
    "ax.plot(x_axis, input_dim_line, label='input_dim=784', linestyle='dashed', color='red', linewidth='2')\n",
    "ax.plot(x_axis, n_h_256_rank_list_dict['l3.weight'], label='n_h=256', linewidth='2')\n",
    "ax.plot(x_axis, n_h_512_rank_list_dict['l3.weight'], label='n_h=512', linewidth='2')\n",
    "ax.plot(x_axis, n_h_1024_rank_list_dict['l3.weight'], label='n_h=1024', linewidth='2')\n",
    "ax.plot(x_axis, n_h_2048_rank_list_dict['l3.weight'], label='n_h=2048', linewidth='2')\n",
    "ax.plot(x_axis, n_h_2048_rank_list_dict_OnE['l3.weight'], label='n_h=2048_OnE', linewidth='2')\n",
    "ax.plot(x_axis, n_h_2048_rank_list_dict_Spray['l3.weight'], label='n_h=2048_Spray', linewidth='2')\n",
    "\n",
    "ax.set_ylabel('Rank', fontsize=14)\n",
    "ax.set_xlabel('Iterations', fontsize=14) \n",
    "ax.legend(fontsize=12)\n",
    "\n",
    "fig.tight_layout(w_pad=0.5)\n",
    "plt.show()\n",
    "fig.savefig('./figure_3_left.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 3 (right): Hadamard transfrom breaks training degeneracy\n",
    "\n",
    "We show that when initializing dimension-increasing layer with Hadamard transform, the rank constraints (training degeneracy) not exsist any more. The rank can be greater than the input dimension during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nothing extra to be done to OnE-Initialize torch.Size([784, 784])\n",
      "Spray initializing to value 0.001277139208173691\n",
      "OnE-Initializing torch.Size([1024, 784])\n",
      "Spray initializing to value 0.001277139208173691\n",
      "Nothing extra to be done to OnE-Initialize torch.Size([1024, 1024])\n",
      "Spray initializing to value 0.0009775171065493646\n",
      "Nothing extra to be done to OnE-Initialize torch.Size([10, 1024])\n",
      "Spray initializing to value 0.0009775171065493646\n",
      " ---------- Now training init=ZerO ----------\n",
      "v ===== Before training (args.init=ZerO) =====\n",
      "torch.Size([784, 784])\n",
      "l1.weight tensor([[0.0000, 0.0013, 0.0013,  ..., 0.0013, 0.0013, 0.0013],\n",
      "        [0.0013, 0.0000, 0.0013,  ..., 0.0013, 0.0013, 0.0013],\n",
      "        [0.0013, 0.0013, 0.0000,  ..., 0.0013, 0.0013, 0.0013],\n",
      "        ...,\n",
      "        [0.0013, 0.0013, 0.0013,  ..., 0.0000, 0.0013, 0.0013],\n",
      "        [0.0013, 0.0013, 0.0013,  ..., 0.0013, 0.0000, 0.0013],\n",
      "        [0.0013, 0.0013, 0.0013,  ..., 0.0013, 0.0013, 0.0000]])\n",
      "torch.Size([1024, 784])\n",
      "l2.weight tensor([[0.0000, 0.0013, 0.0013,  ..., 0.0013, 0.0013, 0.0013],\n",
      "        [0.0013, 0.0000, 0.0013,  ..., 0.0013, 0.0013, 0.0013],\n",
      "        [0.0013, 0.0013, 0.0000,  ..., 0.0013, 0.0013, 0.0013],\n",
      "        ...,\n",
      "        [0.0013, 0.0013, 0.0013,  ..., 0.0013, 0.0013, 0.0013],\n",
      "        [0.0013, 0.0013, 0.0013,  ..., 0.0013, 0.0013, 0.0013],\n",
      "        [0.0013, 0.0013, 0.0013,  ..., 0.0013, 0.0013, 0.0013]])\n",
      "torch.Size([1024, 1024])\n",
      "l3.weight tensor([[0.0000, 0.0010, 0.0010,  ..., 0.0010, 0.0010, 0.0010],\n",
      "        [0.0010, 0.0000, 0.0010,  ..., 0.0010, 0.0010, 0.0010],\n",
      "        [0.0010, 0.0010, 0.0000,  ..., 0.0010, 0.0010, 0.0010],\n",
      "        ...,\n",
      "        [0.0010, 0.0010, 0.0010,  ..., 0.0000, 0.0010, 0.0010],\n",
      "        [0.0010, 0.0010, 0.0010,  ..., 0.0010, 0.0000, 0.0010],\n",
      "        [0.0010, 0.0010, 0.0010,  ..., 0.0010, 0.0010, 0.0000]])\n",
      "torch.Size([10, 1024])\n",
      "l4.weight tensor([[0.0000, 0.0010, 0.0010,  ..., 0.0010, 0.0010, 0.0010],\n",
      "        [0.0010, 0.0000, 0.0010,  ..., 0.0010, 0.0010, 0.0010],\n",
      "        [0.0010, 0.0010, 0.0000,  ..., 0.0010, 0.0010, 0.0010],\n",
      "        ...,\n",
      "        [0.0010, 0.0010, 0.0010,  ..., 0.0010, 0.0010, 0.0010],\n",
      "        [0.0010, 0.0010, 0.0010,  ..., 0.0010, 0.0010, 0.0010],\n",
      "        [0.0010, 0.0010, 0.0010,  ..., 0.0010, 0.0010, 0.0010]])\n",
      "^ ===== Before training (args.init=ZerO) =====\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.302585\tAccuracy(0%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13499/2007514160.py:26: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [3200/60000 (5%)]\tLoss: 2.222609\tAccuracy(1%)\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 2.079185\tAccuracy(1%)\n",
      "Train Epoch: 1 [9600/60000 (16%)]\tLoss: 2.032076\tAccuracy(2%)\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 2.002505\tAccuracy(2%)\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 2.112385\tAccuracy(3%)\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 2.033339\tAccuracy(3%)\n",
      "Train Epoch: 1 [22400/60000 (37%)]\tLoss: 2.077976\tAccuracy(4%)\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 2.079851\tAccuracy(4%)\n",
      "Train Epoch: 1 [28800/60000 (48%)]\tLoss: 2.013998\tAccuracy(5%)\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 1.983075\tAccuracy(5%)\n",
      "Train Epoch: 1 [35200/60000 (59%)]\tLoss: 2.077300\tAccuracy(6%)\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 1.917917\tAccuracy(6%)\n",
      "Train Epoch: 1 [41600/60000 (69%)]\tLoss: 1.967352\tAccuracy(7%)\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 1.982028\tAccuracy(7%)\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 1.860477\tAccuracy(8%)\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 1.905072\tAccuracy(8%)\n",
      "Train Epoch: 1 [54400/60000 (91%)]\tLoss: 2.204276\tAccuracy(9%)\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 1.976593\tAccuracy(10%)\n",
      "\n",
      "Test set: Average loss: 1.9640, Accuracy: 980/10000 (10%)\n",
      "\n",
      "v ===== After training (args.init=ZerO) =====\n",
      "torch.Size([784, 784])\n",
      "l1.weight tensor([[0.0000, 0.0013, 0.0013,  ..., 0.0013, 0.0013, 0.0013],\n",
      "        [0.0013, 0.0000, 0.0013,  ..., 0.0013, 0.0013, 0.0013],\n",
      "        [0.0013, 0.0013, 0.0000,  ..., 0.0013, 0.0013, 0.0013],\n",
      "        ...,\n",
      "        [0.0013, 0.0013, 0.0013,  ..., 0.0000, 0.0013, 0.0013],\n",
      "        [0.0013, 0.0013, 0.0013,  ..., 0.0013, 0.0000, 0.0013],\n",
      "        [0.0013, 0.0013, 0.0013,  ..., 0.0013, 0.0013, 0.0000]])\n",
      "torch.Size([1024, 784])\n",
      "l2.weight tensor([[0.0003, 0.0016, 0.0016,  ..., 0.0016, 0.0016, 0.0016],\n",
      "        [0.0016, 0.0003, 0.0016,  ..., 0.0016, 0.0016, 0.0016],\n",
      "        [0.0016, 0.0016, 0.0003,  ..., 0.0016, 0.0016, 0.0016],\n",
      "        ...,\n",
      "        [0.0016, 0.0016, 0.0016,  ..., 0.0016, 0.0016, 0.0016],\n",
      "        [0.0016, 0.0016, 0.0016,  ..., 0.0016, 0.0016, 0.0016],\n",
      "        [0.0016, 0.0016, 0.0016,  ..., 0.0016, 0.0016, 0.0016]])\n",
      "torch.Size([1024, 1024])\n",
      "l3.weight tensor([[0.0010, 0.0020, 0.0020,  ..., 0.0020, 0.0020, 0.0020],\n",
      "        [0.0021, 0.0011, 0.0021,  ..., 0.0021, 0.0021, 0.0021],\n",
      "        [0.0020, 0.0020, 0.0010,  ..., 0.0020, 0.0020, 0.0020],\n",
      "        ...,\n",
      "        [0.0020, 0.0020, 0.0020,  ..., 0.0010, 0.0020, 0.0020],\n",
      "        [0.0020, 0.0020, 0.0020,  ..., 0.0020, 0.0010, 0.0020],\n",
      "        [0.0020, 0.0020, 0.0020,  ..., 0.0020, 0.0020, 0.0010]])\n",
      "torch.Size([10, 1024])\n",
      "l4.weight tensor([[ 0.0233,  0.0247,  0.0242,  ...,  0.0244,  0.0244,  0.0244],\n",
      "        [-0.0275, -0.0290, -0.0276,  ..., -0.0277, -0.0277, -0.0277],\n",
      "        [ 0.0205,  0.0210,  0.0197,  ...,  0.0208,  0.0208,  0.0208],\n",
      "        ...,\n",
      "        [-0.0256, -0.0262, -0.0257,  ..., -0.0259, -0.0259, -0.0259],\n",
      "        [ 0.0114,  0.0117,  0.0115,  ...,  0.0115,  0.0115,  0.0115],\n",
      "        [-0.0245, -0.0251, -0.0246,  ..., -0.0248, -0.0248, -0.0248]])\n",
      "^ ===== After training (args.init=ZerO) =====\n",
      "Nothing extra to be done to OnE-Initialize torch.Size([784, 784])\n",
      "OnE-Initializing torch.Size([1024, 784])\n",
      "Nothing extra to be done to OnE-Initialize torch.Size([1024, 1024])\n",
      "Nothing extra to be done to OnE-Initialize torch.Size([10, 1024])\n",
      " ---------- Now training init=ZerO ----------\n",
      "v ===== Before training (args.init=ZerO) =====\n",
      "torch.Size([784, 784])\n",
      "l1.weight tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.]])\n",
      "torch.Size([1024, 784])\n",
      "l2.weight tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "torch.Size([1024, 1024])\n",
      "l3.weight tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.]])\n",
      "torch.Size([10, 1024])\n",
      "l4.weight tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "^ ===== Before training (args.init=ZerO) =====\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.302585\tAccuracy(0%)\n",
      "Train Epoch: 1 [3200/60000 (5%)]\tLoss: 0.366084\tAccuracy(4%)\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.386167\tAccuracy(9%)\n",
      "Train Epoch: 1 [9600/60000 (16%)]\tLoss: 0.532356\tAccuracy(13%)\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.240619\tAccuracy(18%)\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.538828\tAccuracy(23%)\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.168827\tAccuracy(28%)\n",
      "Train Epoch: 1 [22400/60000 (37%)]\tLoss: 0.645882\tAccuracy(32%)\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.306740\tAccuracy(37%)\n",
      "Train Epoch: 1 [28800/60000 (48%)]\tLoss: 0.343384\tAccuracy(42%)\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.131351\tAccuracy(47%)\n",
      "Train Epoch: 1 [35200/60000 (59%)]\tLoss: 0.097861\tAccuracy(52%)\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.293087\tAccuracy(57%)\n",
      "Train Epoch: 1 [41600/60000 (69%)]\tLoss: 0.083357\tAccuracy(62%)\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.102314\tAccuracy(67%)\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.109509\tAccuracy(72%)\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.194064\tAccuracy(77%)\n",
      "Train Epoch: 1 [54400/60000 (91%)]\tLoss: 0.313322\tAccuracy(82%)\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.083775\tAccuracy(87%)\n",
      "\n",
      "Test set: Average loss: 0.1626, Accuracy: 9507/10000 (95%)\n",
      "\n",
      "v ===== After training (args.init=ZerO) =====\n",
      "torch.Size([784, 784])\n",
      "l1.weight tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.]])\n",
      "torch.Size([1024, 784])\n",
      "l2.weight tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "torch.Size([1024, 1024])\n",
      "l3.weight tensor([[ 1.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  1.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  1.0000e+00,  ...,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00],\n",
      "        ...,\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  1.0001e+00,\n",
      "         -1.5400e-05,  6.9062e-05],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.2628e-04,\n",
      "          1.0009e+00,  3.5211e-04],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -8.5746e-04,\n",
      "         -9.0657e-04,  1.0071e+00]])\n",
      "torch.Size([10, 1024])\n",
      "l4.weight tensor([[ 1.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  6.7383e-04,\n",
      "         -7.0087e-03,  1.4689e-02],\n",
      "        [ 0.0000e+00,  1.0000e+00,  0.0000e+00,  ..., -2.3857e-03,\n",
      "         -2.0831e-04, -6.9033e-02],\n",
      "        [ 0.0000e+00,  0.0000e+00,  1.0000e+00,  ...,  6.2845e-03,\n",
      "          8.1663e-03, -1.1530e-01],\n",
      "        ...,\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  2.8619e-04,\n",
      "         -2.2932e-03, -3.9102e-02],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  7.4428e-03,\n",
      "         -4.0435e-03, -9.4243e-04],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -4.5987e-03,\n",
      "         -6.8318e-03,  2.9913e-02]])\n",
      "^ ===== After training (args.init=ZerO) =====\n",
      " ---------- Now training init=ZerO ----------\n",
      "v ===== Before training (args.init=ZerO) =====\n",
      "torch.Size([784, 784])\n",
      "l1.weight tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.]])\n",
      "torch.Size([1024, 784])\n",
      "l2.weight tensor([[ 0.0312,  0.0312,  0.0312,  ...,  0.0312,  0.0312,  0.0312],\n",
      "        [ 0.0312, -0.0312,  0.0312,  ..., -0.0312,  0.0312, -0.0312],\n",
      "        [ 0.0312,  0.0312, -0.0312,  ...,  0.0312, -0.0312, -0.0312],\n",
      "        ...,\n",
      "        [ 0.0312, -0.0312,  0.0312,  ..., -0.0312,  0.0312, -0.0312],\n",
      "        [ 0.0312,  0.0312, -0.0312,  ...,  0.0312, -0.0312, -0.0312],\n",
      "        [ 0.0312, -0.0312, -0.0312,  ..., -0.0312, -0.0312,  0.0312]])\n",
      "torch.Size([1024, 1024])\n",
      "l3.weight tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.]])\n",
      "torch.Size([10, 1024])\n",
      "l4.weight tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "^ ===== Before training (args.init=ZerO) =====\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 3.204832\tAccuracy(0%)\n",
      "Train Epoch: 1 [3200/60000 (5%)]\tLoss: 0.313350\tAccuracy(4%)\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.319433\tAccuracy(9%)\n",
      "Train Epoch: 1 [9600/60000 (16%)]\tLoss: 0.501207\tAccuracy(13%)\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.189326\tAccuracy(18%)\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.520636\tAccuracy(23%)\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.158095\tAccuracy(28%)\n",
      "Train Epoch: 1 [22400/60000 (37%)]\tLoss: 0.586473\tAccuracy(33%)\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.260996\tAccuracy(38%)\n",
      "Train Epoch: 1 [28800/60000 (48%)]\tLoss: 0.329167\tAccuracy(43%)\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.112401\tAccuracy(48%)\n",
      "Train Epoch: 1 [35200/60000 (59%)]\tLoss: 0.080823\tAccuracy(53%)\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.228567\tAccuracy(58%)\n",
      "Train Epoch: 1 [41600/60000 (69%)]\tLoss: 0.055384\tAccuracy(63%)\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.092666\tAccuracy(68%)\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.069544\tAccuracy(73%)\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.169860\tAccuracy(78%)\n",
      "Train Epoch: 1 [54400/60000 (91%)]\tLoss: 0.292203\tAccuracy(83%)\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.069095\tAccuracy(88%)\n",
      "\n",
      "Test set: Average loss: 0.1502, Accuracy: 9544/10000 (95%)\n",
      "\n",
      "v ===== After training (args.init=ZerO) =====\n",
      "torch.Size([784, 784])\n",
      "l1.weight tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.]])\n",
      "torch.Size([1024, 784])\n",
      "l2.weight tensor([[ 0.0312,  0.0312,  0.0312,  ...,  0.0312,  0.0312,  0.0312],\n",
      "        [ 0.0312, -0.0312,  0.0312,  ..., -0.0312,  0.0312, -0.0312],\n",
      "        [ 0.0312,  0.0312, -0.0312,  ...,  0.0312, -0.0312, -0.0312],\n",
      "        ...,\n",
      "        [ 0.0312, -0.0312,  0.0312,  ..., -0.0312,  0.0312, -0.0312],\n",
      "        [ 0.0312,  0.0312, -0.0312,  ...,  0.0312, -0.0312, -0.0312],\n",
      "        [ 0.0312, -0.0312, -0.0312,  ..., -0.0312, -0.0312,  0.0312]])\n",
      "torch.Size([1024, 1024])\n",
      "l3.weight tensor([[ 1.0792e+00, -1.6253e-02, -7.2578e-02,  ..., -5.4269e-03,\n",
      "          2.8565e-05, -8.6293e-03],\n",
      "        [-1.6179e-01,  1.2150e+00,  3.7637e-03,  ...,  1.5216e-03,\n",
      "         -3.7685e-03,  3.0927e-03],\n",
      "        [ 7.1769e-02,  1.0744e-02,  1.1465e+00,  ..., -7.7749e-04,\n",
      "          2.9988e-03, -5.3003e-03],\n",
      "        ...,\n",
      "        [-6.8089e-04, -9.5977e-04, -2.6339e-04,  ...,  1.0002e+00,\n",
      "          2.0938e-04,  1.0082e-04],\n",
      "        [-1.1107e-03, -1.0278e-03,  9.3397e-04,  ...,  1.9351e-04,\n",
      "          1.0001e+00,  3.2419e-05],\n",
      "        [-2.3491e-03,  3.7793e-05, -1.4508e-03,  ...,  1.4941e-04,\n",
      "          6.2993e-05,  1.0000e+00]])\n",
      "torch.Size([10, 1024])\n",
      "l4.weight tensor([[ 1.2411e+00, -4.7199e-02, -1.0321e-01,  ..., -5.3784e-03,\n",
      "         -1.1988e-03, -8.4532e-03],\n",
      "        [-1.0908e-01,  1.3595e+00, -1.6572e-02,  ...,  1.5397e-03,\n",
      "         -1.8692e-03,  1.9083e-03],\n",
      "        [ 1.1326e-01, -1.6533e-02,  1.3304e+00,  ..., -1.6743e-03,\n",
      "          2.7040e-03, -6.3981e-03],\n",
      "        ...,\n",
      "        [-2.5509e-02,  9.3963e-02,  1.6305e-01,  ..., -2.2983e-03,\n",
      "          3.2898e-03, -4.1319e-03],\n",
      "        [-6.8902e-02, -1.0127e-01, -6.2287e-02,  ...,  1.6266e-02,\n",
      "          1.8535e-02,  6.6049e-04],\n",
      "        [ 1.7682e-02, -4.7501e-02, -2.5815e-01,  ...,  8.6056e-03,\n",
      "          2.8480e-03,  1.1957e-02]])\n",
      "^ ===== After training (args.init=ZerO) =====\n",
      "Init matrix torch.Size([784, 784]) with m=784, n=784\n",
      "Init matrix torch.Size([1024, 784]) with m=1024, n=784\n",
      "Init matrix torch.Size([1024, 1024]) with m=1024, n=1024\n",
      "Init matrix torch.Size([10, 1024]) with m=10, n=1024\n",
      " ---------- Now training init=ZerO ----------\n",
      "v ===== Before training (args.init=ZerO) =====\n",
      "torch.Size([784, 784])\n",
      "l1.weight tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.]])\n",
      "torch.Size([1024, 784])\n",
      "l2.weight tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "torch.Size([1024, 1024])\n",
      "l3.weight tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.]])\n",
      "torch.Size([10, 1024])\n",
      "l4.weight tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "^ ===== Before training (args.init=ZerO) =====\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.302585\tAccuracy(0%)\n",
      "Train Epoch: 1 [3200/60000 (5%)]\tLoss: 0.387518\tAccuracy(4%)\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.401102\tAccuracy(9%)\n",
      "Train Epoch: 1 [9600/60000 (16%)]\tLoss: 0.541363\tAccuracy(13%)\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.241735\tAccuracy(18%)\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.560055\tAccuracy(23%)\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.180239\tAccuracy(27%)\n",
      "Train Epoch: 1 [22400/60000 (37%)]\tLoss: 0.678365\tAccuracy(32%)\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.327334\tAccuracy(37%)\n",
      "Train Epoch: 1 [28800/60000 (48%)]\tLoss: 0.341815\tAccuracy(42%)\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.138724\tAccuracy(47%)\n",
      "Train Epoch: 1 [35200/60000 (59%)]\tLoss: 0.099397\tAccuracy(52%)\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.284145\tAccuracy(57%)\n",
      "Train Epoch: 1 [41600/60000 (69%)]\tLoss: 0.101840\tAccuracy(62%)\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.110993\tAccuracy(67%)\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.112484\tAccuracy(72%)\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.192544\tAccuracy(77%)\n",
      "Train Epoch: 1 [54400/60000 (91%)]\tLoss: 0.324636\tAccuracy(82%)\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.087515\tAccuracy(87%)\n",
      "\n",
      "Test set: Average loss: 0.1659, Accuracy: 9507/10000 (95%)\n",
      "\n",
      "v ===== After training (args.init=ZerO) =====\n",
      "torch.Size([784, 784])\n",
      "l1.weight tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.]])\n",
      "torch.Size([1024, 784])\n",
      "l2.weight tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "torch.Size([1024, 1024])\n",
      "l3.weight tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.]])\n",
      "torch.Size([10, 1024])\n",
      "l4.weight tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 1.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "^ ===== After training (args.init=ZerO) =====\n",
      " ---------- Now training init=ZerO ----------\n",
      "v ===== Before training (args.init=ZerO) =====\n",
      "torch.Size([784, 784])\n",
      "l1.weight tensor([[ 0.0201,  0.0503,  0.0700,  ...,  0.0056, -0.0191, -0.0746],\n",
      "        [ 0.0666, -0.0243,  0.0235,  ..., -0.0355, -0.0771,  0.0545],\n",
      "        [ 0.0409, -0.0016,  0.0712,  ..., -0.0156, -0.0044,  0.0105],\n",
      "        ...,\n",
      "        [ 0.0744, -0.0808,  0.0199,  ..., -0.0243, -0.0044,  0.0383],\n",
      "        [-0.0387,  0.0667, -0.0020,  ..., -0.0293, -0.0265, -0.0952],\n",
      "        [ 0.0540,  0.0250, -0.0414,  ..., -0.0684, -0.0407,  0.0343]])\n",
      "torch.Size([1024, 784])\n",
      "l2.weight tensor([[-0.0168,  0.0218,  0.0190,  ..., -0.0111,  0.0377, -0.0083],\n",
      "        [-0.0052, -0.0441, -0.0399,  ..., -0.0411, -0.0212, -0.0735],\n",
      "        [ 0.0191, -0.0336,  0.0178,  ..., -0.0766,  0.0653,  0.0089],\n",
      "        ...,\n",
      "        [ 0.0280, -0.1188, -0.0371,  ..., -0.0215,  0.0161,  0.0026],\n",
      "        [ 0.0519, -0.0013, -0.0097,  ..., -0.0343,  0.0263,  0.0216],\n",
      "        [-0.0265,  0.0718,  0.0696,  ..., -0.0436,  0.1138,  0.0248]])\n",
      "torch.Size([1024, 1024])\n",
      "l3.weight tensor([[-1.6743e-02,  1.0081e-02, -8.8099e-02,  ...,  2.7471e-03,\n",
      "         -2.9532e-02, -4.7705e-03],\n",
      "        [-3.6494e-02,  9.4931e-03,  2.2656e-02,  ..., -2.8350e-02,\n",
      "          3.2992e-02, -1.0237e-02],\n",
      "        [ 1.3138e-01, -1.5157e-02,  7.0867e-02,  ..., -8.3613e-05,\n",
      "         -6.9518e-03, -3.6540e-03],\n",
      "        ...,\n",
      "        [-3.8594e-02, -8.3653e-02, -2.7728e-02,  ...,  4.4013e-02,\n",
      "         -3.0070e-02,  5.7402e-02],\n",
      "        [ 4.0196e-03, -2.5625e-02,  1.4508e-02,  ...,  3.9420e-02,\n",
      "         -1.0473e-01, -1.1434e-01],\n",
      "        [-1.9194e-02,  5.8001e-02, -5.2332e-02,  ..., -5.3641e-02,\n",
      "         -5.6861e-02,  2.2894e-02]])\n",
      "torch.Size([10, 1024])\n",
      "l4.weight tensor([[-0.0324, -0.0252, -0.0033,  ..., -0.0356,  0.0581, -0.0279],\n",
      "        [ 0.0206,  0.0602, -0.0344,  ..., -0.0410,  0.0041,  0.0040],\n",
      "        [-0.0557,  0.0499,  0.0282,  ...,  0.0481, -0.0033, -0.0743],\n",
      "        ...,\n",
      "        [-0.0095, -0.0216, -0.0787,  ..., -0.0096, -0.0018, -0.0499],\n",
      "        [-0.0912,  0.0384, -0.0085,  ..., -0.0120, -0.0916,  0.0099],\n",
      "        [-0.0095, -0.0179,  0.0334,  ...,  0.0830, -0.0068, -0.0103]])\n",
      "^ ===== Before training (args.init=ZerO) =====\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.354125\tAccuracy(0%)\n",
      "Train Epoch: 1 [3200/60000 (5%)]\tLoss: 0.292689\tAccuracy(4%)\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.298670\tAccuracy(8%)\n",
      "Train Epoch: 1 [9600/60000 (16%)]\tLoss: 0.394753\tAccuracy(13%)\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.159087\tAccuracy(18%)\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.394199\tAccuracy(23%)\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.112931\tAccuracy(28%)\n",
      "Train Epoch: 1 [22400/60000 (37%)]\tLoss: 0.523944\tAccuracy(33%)\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.212017\tAccuracy(38%)\n",
      "Train Epoch: 1 [28800/60000 (48%)]\tLoss: 0.237420\tAccuracy(43%)\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.082517\tAccuracy(48%)\n",
      "Train Epoch: 1 [35200/60000 (59%)]\tLoss: 0.088909\tAccuracy(53%)\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.225549\tAccuracy(58%)\n",
      "Train Epoch: 1 [41600/60000 (69%)]\tLoss: 0.039499\tAccuracy(63%)\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.039899\tAccuracy(68%)\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.078862\tAccuracy(74%)\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.110236\tAccuracy(79%)\n",
      "Train Epoch: 1 [54400/60000 (91%)]\tLoss: 0.236993\tAccuracy(84%)\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.051369\tAccuracy(89%)\n",
      "\n",
      "Test set: Average loss: 0.1541, Accuracy: 9511/10000 (95%)\n",
      "\n",
      "v ===== After training (args.init=ZerO) =====\n",
      "torch.Size([784, 784])\n",
      "l1.weight tensor([[ 0.0201,  0.0503,  0.0700,  ...,  0.0056, -0.0191, -0.0746],\n",
      "        [ 0.0666, -0.0243,  0.0235,  ..., -0.0355, -0.0771,  0.0545],\n",
      "        [ 0.0409, -0.0016,  0.0712,  ..., -0.0156, -0.0044,  0.0105],\n",
      "        ...,\n",
      "        [ 0.0744, -0.0808,  0.0199,  ..., -0.0243, -0.0044,  0.0383],\n",
      "        [-0.0387,  0.0667, -0.0020,  ..., -0.0293, -0.0265, -0.0952],\n",
      "        [ 0.0540,  0.0250, -0.0414,  ..., -0.0684, -0.0407,  0.0343]])\n",
      "torch.Size([1024, 784])\n",
      "l2.weight tensor([[-0.0170,  0.0218,  0.0191,  ..., -0.0114,  0.0375, -0.0096],\n",
      "        [-0.0045, -0.0434, -0.0421,  ..., -0.0411, -0.0208, -0.0716],\n",
      "        [ 0.0186, -0.0346,  0.0078,  ..., -0.0766,  0.0647,  0.0068],\n",
      "        ...,\n",
      "        [ 0.0278, -0.1187, -0.0356,  ..., -0.0210,  0.0166,  0.0025],\n",
      "        [ 0.0519, -0.0021, -0.0075,  ..., -0.0346,  0.0250,  0.0207],\n",
      "        [-0.0268,  0.0731,  0.0697,  ..., -0.0429,  0.1123,  0.0263]])\n",
      "torch.Size([1024, 1024])\n",
      "l3.weight tensor([[-0.0164,  0.0108, -0.0874,  ...,  0.0016, -0.0339, -0.0034],\n",
      "        [-0.0365,  0.0094,  0.0293,  ..., -0.0284,  0.0371, -0.0093],\n",
      "        [ 0.1314, -0.0147,  0.0777,  ...,  0.0008, -0.0047,  0.0025],\n",
      "        ...,\n",
      "        [-0.0382, -0.0827, -0.0200,  ...,  0.0440, -0.0191,  0.0604],\n",
      "        [ 0.0041, -0.0254,  0.0166,  ...,  0.0400, -0.1028, -0.1143],\n",
      "        [-0.0192,  0.0566, -0.0593,  ..., -0.0532, -0.0612,  0.0282]])\n",
      "torch.Size([10, 1024])\n",
      "l4.weight tensor([[-0.0597, -0.0025, -0.0184,  ..., -0.0584,  0.0475, -0.0485],\n",
      "        [ 0.0937,  0.0700, -0.0398,  ..., -0.1017,  0.0162,  0.0040],\n",
      "        [-0.0557,  0.0753,  0.0562,  ...,  0.1147,  0.0052, -0.1428],\n",
      "        ...,\n",
      "        [ 0.0398, -0.0187, -0.1163,  ..., -0.0490,  0.0116, -0.0759],\n",
      "        [-0.0871,  0.0349, -0.0120,  ...,  0.0620, -0.1044,  0.0274],\n",
      "        [ 0.0039, -0.0136,  0.0463,  ...,  0.0944, -0.0055,  0.0136]])\n",
      "^ ===== After training (args.init=ZerO) =====\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m partial_identity_init_rank_list_dict \u001b[38;5;241m=\u001b[39m train_model(MLP(init\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPartial_Identity\u001b[39m\u001b[38;5;124m'\u001b[39m, n_h\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1024\u001b[39m))\n\u001b[1;32m      5\u001b[0m random_init_rank_list_dict \u001b[38;5;241m=\u001b[39m train_model(MLP(init\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRandom\u001b[39m\u001b[38;5;124m'\u001b[39m, n_h\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1024\u001b[39m))\n\u001b[0;32m----> 7\u001b[0m fig, ax \u001b[38;5;241m=\u001b[39m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m, figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m5\u001b[39m,\u001b[38;5;241m4\u001b[39m), gridspec_kw \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwspace\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhspace\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m0.5\u001b[39m})\n\u001b[1;32m      9\u001b[0m x_axis \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mlen\u001b[39m(n_h_512_rank_list_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml3.weight\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     10\u001b[0m x_axis \u001b[38;5;241m=\u001b[39m x_axis \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m50\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "Spray_init_rank_list_dict = train_model(MLP(init='Spray', n_h=1024))\n",
    "OnE_init_rank_list_dict = train_model(MLP(init='OnE', n_h=1024))\n",
    "ZerO_init_rank_list_dict = train_model(MLP(init='ZerO', n_h=1024))\n",
    "partial_identity_init_rank_list_dict = train_model(MLP(init='Partial_Identity', n_h=1024))\n",
    "random_init_rank_list_dict = train_model(MLP(init='Random', n_h=1024))\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(5,4), gridspec_kw = {'wspace':0.5, 'hspace':0.5})\n",
    "\n",
    "x_axis = np.arange(1, len(n_h_512_rank_list_dict['l3.weight'])+1)\n",
    "x_axis = x_axis * 50\n",
    "\n",
    "# generate a line of 784\n",
    "input_dim_line = np.ones(len(n_h_512_rank_list_dict['l3.weight'])) * 784\n",
    "\n",
    "ax.plot(x_axis, input_dim_line, label='input_dim=784', linestyle='dashed', color='red', linewidth='2')\n",
    "ax.plot(x_axis, random_init_rank_list_dict['l3.weight'], label='Random Init', linewidth='2')\n",
    "ax.plot(x_axis, partial_identity_init_rank_list_dict['l3.weight'], label='Partial Identity Init', linewidth='2')\n",
    "ax.plot(x_axis, ZerO_init_rank_list_dict['l3.weight'], label='ZerO Init', linewidth='2')\n",
    "ax.plot(x_axis, OnE_init_rank_list_dict['l3.weight'], label='OnE Init', linewidth='2')\n",
    "ax.plot(x_axis, Spray_init_rank_list_dict['l3.weight'], label='Spray Init', linewidth='2')\n",
    "\n",
    "\n",
    "ax.set_ylabel('Rank', fontsize=14)\n",
    "ax.set_xlabel('Iterations', fontsize=14) \n",
    "ax.legend(fontsize=12)\n",
    "\n",
    "fig.tight_layout(w_pad=0.5)\n",
    "plt.show()\n",
    "fig.savefig('./figure_3_right.pdf', bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
